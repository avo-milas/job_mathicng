{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aaderevyagin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/aaderevyagin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRanker, Pool, MetricVisualizer\n",
    "from copy import deepcopy\n",
    "from data.heuristic_extractor import HeuristicExtractor\n",
    "from data.llm_extractor import LlmExtractor\n",
    "from data.resume_extractor import ResumeExtractor\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CatBoostVacancyRanker:           \n",
    "            \n",
    "    def form_train_sequence(self, vacancy_dataset, user_dataset, index, is_train=True):\n",
    "        count_skipped = 0\n",
    "        user_dict = user_dataset.iloc[index]\n",
    "        vacancy_uuid = user_dict['vacancy_uuid']\n",
    "        vacancy_dict = vacancy_dataset[vacancy_dataset['vacancy_uuid'] == vacancy_uuid].iloc[0]\n",
    "\n",
    "        result_dict = {}\n",
    "\n",
    "        # Formulate features\n",
    "\n",
    "        for grade_type in ['junior', 'middle', 'senior']:\n",
    "            result_dict[f'{grade_type}_match'] = (user_dict[f'is_{grade_type}'] == vacancy_dict[f'is_{grade_type}'])\n",
    "\n",
    "        user_hard_skills = set(user_dict['key_skills'])\n",
    "        user_extra_skills = set(user_dict['extra_skills'])\n",
    "        vacancy_hard_skills = set(vacancy_dict['hard_skills'])\n",
    "        vacancy_extra_skills = set(vacancy_dict['extra_skills'])\n",
    "\n",
    "        result_dict['hard_skills_intersection'] = len(vacancy_hard_skills) / max(len(vacancy_hard_skills.union(user_hard_skills)), 1)\n",
    "        # result_dict['soft_skills_intersection'] = len(vacancy_extra_skills) / max(len(vacancy_extra_skills.union(user_extra_skills)), 1)\n",
    "        result_dict['working_months'] = int(user_dict['working_months'])\n",
    "        if vacancy_dict['monthly_wage'] is not None and vacancy_dict['monthly_wage'] != 'null':\n",
    "            result_dict['monthly_wage'] = int(vacancy_dict['monthly_wage']) / 1000\n",
    "        else:\n",
    "            count_skipped += 1\n",
    "            result_dict['monthly_wage'] = None\n",
    "        try:\n",
    "            result_dict['experience'] = int(vacancy_dict['experience'])\n",
    "        except ValueError:\n",
    "            count_skipped += 1\n",
    "            result_dict['experience'] = None\n",
    "        result_dict['age'] = user_dict['age']\n",
    "        result_dict['benefits'] = vacancy_dict['benefits']\n",
    "        if is_train:\n",
    "            result_dict['relevance'] = user_dict['relevance']\n",
    "            result_dict['group'] = self.vacancies_compress[user_dict['vacancy_uuid']]\n",
    "            result_dict['weights'] = np.float64(3 if result_dict['monthly_wage'] is not None and result_dict['monthly_wage'] >= 200 else 1)\n",
    "\n",
    "        return result_dict\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, vacancies):\n",
    "        heuristic_extractor = HeuristicExtractor(vacancies)\n",
    "        resume_extractor = ResumeExtractor(vacancies)\n",
    "        llm_extractor = LlmExtractor(vacancies)\n",
    "\n",
    "        heuristic_dataset = heuristic_extractor.form_dataset()\n",
    "        llm_dataset = llm_extractor.form_dataset()\n",
    "        resume_dataset = resume_extractor.form_dataset()\n",
    "\n",
    "        self.vacancies_compress = {}\n",
    "        for index, item in enumerate(vacancies):\n",
    "            self.vacancies_compress[item['vacancy']['uuid']] = index\n",
    "\n",
    "        cumulative_data = [self.form_train_sequence(llm_dataset, resume_dataset, index) for index in range(len(resume_dataset))]\n",
    "        preprocessed_train = pd.DataFrame.from_dict(cumulative_data).sort_values(by=['group'])\n",
    "        \n",
    "        indexes = np.arange(len(self.vacancies_compress))\n",
    "        np.random.shuffle(indexes)\n",
    "        group_tr, group_te = indexes[:25], indexes[25:]\n",
    "        train_indexes, test_indexes = [], []\n",
    "        for index, row in preprocessed_train.iterrows():\n",
    "            if index in group_tr:\n",
    "                train_indexes.append(index)\n",
    "            else:\n",
    "                test_indexes.append(index)\n",
    "\n",
    "        train_indexes = np.array(train_indexes)\n",
    "        test_indexes = np.array(test_indexes)\n",
    "\n",
    "        X_train, X_test = preprocessed_train.iloc[train_indexes], preprocessed_train.iloc[test_indexes]\n",
    "\n",
    "        y_train = X_train['relevance']\n",
    "        train_groups = X_train['group']\n",
    "        X_train.drop(columns=['relevance', 'group', 'weights'], inplace=True)\n",
    "    \n",
    "        y_test = X_test['relevance']\n",
    "        test_groups = X_test['group']\n",
    "        X_test.drop(columns=['relevance', 'group', 'weights'], inplace=True)\n",
    "\n",
    "        train = Pool(\n",
    "            data=X_train,\n",
    "            label=y_train,\n",
    "            group_id=train_groups,\n",
    "        )\n",
    "    \n",
    "        test = Pool(\n",
    "            data=X_test,\n",
    "            label=y_test,\n",
    "            group_id=test_groups,\n",
    "        )\n",
    "\n",
    "        default_parameters = {\n",
    "            'iterations': 400,\n",
    "            'custom_metric': ['NDCG', 'PFound', 'AverageGain:top=10'],\n",
    "            'verbose': False,\n",
    "            'random_seed': 0,\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 1 * 10 ** -4\n",
    "        }\n",
    "\n",
    "        loss_function = 'PairLogit'\n",
    "        additional_params = {'custom_metric': ['PrecisionAt:top=5', 'RecallAt:top=5', 'MAP:top=5', 'NDCG:top=10']}\n",
    "\n",
    "        parameters = deepcopy(default_parameters)\n",
    "        parameters['loss_function'] = loss_function\n",
    "        parameters['train_dir'] = loss_function\n",
    "\n",
    "        if additional_params is not None:\n",
    "            parameters.update(additional_params)\n",
    "\n",
    "        model = CatBoostRanker(**parameters)\n",
    "        model.fit(train, eval_set=test, plot=False)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, vacancy, resumes_id):\n",
    "        new_json = {}\n",
    "        new_json['vacancy'] = vacancy['vacancy']\n",
    "        new_json['resumes'] = []\n",
    "        for i in vacancy['resumes']:\n",
    "            if i['uuid'] in resumes_id:\n",
    "                new_json['resumes'].append(i)\n",
    "\n",
    "        vacancy = new_json\n",
    "        resumes_extractor = ResumeExtractor([vacancy])\n",
    "        resumes_dset = resumes_extractor.form_dataset()\n",
    "        vacancy_dset = LlmExtractor([vacancy], test=True).form_dataset()\n",
    "        description = [self.form_train_sequence(vacancy_dset, resumes_dset, i, is_train=False) for i in range(len(resumes_dset))]\n",
    "        predictions = self.model.predict(pd.DataFrame(description))\n",
    "        indexes = np.argsort(predictions)[::-1]\n",
    "        return np.array(resumes_id)[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_grade data extractor fullness: 14/29\n",
      "get_work_type data extractor fullness: 19/29\n",
      "get_experience data extractor fullness: 12/29\n",
      "get_experience data extractor fullness: 29/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14530/1393792765.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.drop(columns=['relevance', 'group', 'weights'], inplace=True)\n",
      "/tmp/ipykernel_14530/1393792765.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop(columns=['relevance', 'group', 'weights'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['f4f84f9b-6c7a-366d-b8b4-84b0e6f337c7',\n",
       "       '70547288-56fc-3cab-9bef-f752f2e1b21f',\n",
       "       'fd9c4130-177f-3546-8974-189a52fcc496',\n",
       "       '1ed1795c-43b2-304e-8386-bf53d0ebec18',\n",
       "       '6abae195-2cbf-3bbe-8dfb-8d2dcc3e88b6',\n",
       "       '6561771c-7ef3-3e50-ab3a-ba8547201480',\n",
       "       'f111eaab-2416-33f5-8a95-8ec11e8485c4',\n",
       "       'e3a42770-927c-3d59-a761-bcc3549d1054',\n",
       "       '62092df7-1166-3602-b509-a4df3999ffe5',\n",
       "       '6eaade34-b13c-3d17-a573-dfa786cbb0d5',\n",
       "       'c70de373-9f3a-3647-ab66-f25e98c29409',\n",
       "       '9cef8747-af3a-3833-9098-3bfabf1e40eb',\n",
       "       'bd53a1ea-ae17-3506-97b4-287aa8e9cc21',\n",
       "       '3c4020e7-172f-3ed5-adc9-fe9a62097b26',\n",
       "       '5785c202-6744-3e1b-994a-d5bffc6aad14',\n",
       "       'b1357f8e-3c98-3142-81e7-fd729ec50ca0',\n",
       "       '3e3a379f-226e-305e-b7d8-cf341e00cbd7',\n",
       "       'feedc674-8547-35d0-9f63-fd6a3d3fedcd',\n",
       "       'f56395de-af47-3f65-90e9-37d44ea07610',\n",
       "       'd9fffe2b-cba9-3ff2-bd47-b8bfc48cbe89',\n",
       "       '8e193a9a-d338-36b5-800b-45de7a809157',\n",
       "       '156ce0c2-d834-3e8e-ba17-3b35e68bbf10',\n",
       "       'add58503-f251-3291-8bc6-e57afe7fe86d',\n",
       "       'e59d1c07-489b-3299-803f-5dea7da43b56',\n",
       "       '82df355a-235e-3046-9e6e-782ddf1600eb',\n",
       "       '93d61f89-b8d0-3187-8c90-888be29e68dd',\n",
       "       '73592479-12bf-38d4-84f0-91fe33518b47',\n",
       "       '6927466d-20e7-3873-9267-83fc9bfa4037',\n",
       "       'f61558f7-5769-37e0-b03d-80ff86d0a6bf',\n",
       "       'a67850f6-abd4-35ab-a3b0-0de92d2e2293',\n",
       "       '0fc31d5b-a567-3753-8214-9899923545d0',\n",
       "       '7a79f64e-7a87-3008-b8ec-e165a94f72e0',\n",
       "       'd1fde183-f35a-3a06-8f43-c14768e18f9c',\n",
       "       '9a9c3ff1-49f8-30dd-a294-e56fc60cae64',\n",
       "       '6099f6cb-1897-3983-9afb-a71b37ebdc7b',\n",
       "       '1f1809fd-fde5-3720-a5dc-02f1160f53a9',\n",
       "       '64d2b2a9-98df-37a6-a326-a223db297718',\n",
       "       'fac1867b-8ca6-3d94-988e-7dab0d465b7f',\n",
       "       'a71b0749-1ebc-3099-b0a1-342ca64d1575',\n",
       "       '6cf3cee0-c911-30f6-b254-416029f8af3b',\n",
       "       'f6f396d8-5527-3610-8d0d-13768d9b3ec9',\n",
       "       'fbab422e-7e0b-38d2-a7bc-cc7286858c10',\n",
       "       'eb02a87d-d829-36bc-9006-11bceef0ffeb',\n",
       "       '5b52397d-7c55-3f10-82cb-3797709a51e5',\n",
       "       '5ae3b7a0-6028-3bd8-8b4e-27a861503806',\n",
       "       '5cfd26bc-84e6-3714-b54b-746acbca3d18',\n",
       "       'ad355c5f-fa08-3d9e-96e2-73b49d1a390a',\n",
       "       '989b9e34-1ee0-3fa0-8ac8-b4617d7444b7',\n",
       "       'da6466e6-0b6d-36aa-adbf-9f0e4fdd6b3f',\n",
       "       'cc683ed5-8db5-32da-9eab-9433a539b3b5',\n",
       "       '7c95a4d3-d958-3e1e-9075-69eae00c5795',\n",
       "       '0f6a912b-c462-3bec-a632-c219f51e0b3c',\n",
       "       'a5187b56-f86c-3996-8797-57d178821222',\n",
       "       '0825069f-c8ee-3ca9-b4f2-753b7a85688a',\n",
       "       '0f45f507-0b5d-347f-86e2-0f799898f812',\n",
       "       '65b737a6-85cf-33e6-9475-e5164799b35b',\n",
       "       '3bbc8c32-ba6f-3f3f-a469-ea009295a1ab',\n",
       "       '6065ee07-4c42-3cf4-8e45-9d053b9041f7',\n",
       "       '63b33138-5045-31fc-878b-65672a829658',\n",
       "       '19c83c9c-d35b-365d-959b-7efe82a306ea',\n",
       "       '14670cec-aedf-3aa7-aa4e-37486bca0aca',\n",
       "       '9fe9cded-6120-384e-8f9a-96ce33bc99dd',\n",
       "       '639c1eda-c4ec-3319-b2e2-17ad5d87e173',\n",
       "       '8e456229-6e4e-3d57-a90e-ae4c3e1db869',\n",
       "       '270ac4ca-75b8-343f-8b18-2f5ae400ba68',\n",
       "       'd6c4ef10-657d-30b3-80d0-4cf1dda65c4e',\n",
       "       '42eae4bf-4826-3105-b197-dc0afb063714',\n",
       "       '3e9618c4-7ed0-35d7-9c4c-71c06361fc21',\n",
       "       '0fe70aee-589a-3ba7-8479-d8f2f83b0921',\n",
       "       'cc88bf96-f0b9-313a-abce-dbe60b6f1c98',\n",
       "       'f288a532-0b58-30cb-ac3c-f87e53984719',\n",
       "       'aff4b709-ccd2-340a-949f-84b1bb7eb260',\n",
       "       '96354edc-4225-333b-9c37-df48057fcaf8',\n",
       "       '9a802e9b-87ee-3471-973e-3ce544e6de25',\n",
       "       'ebcd86ef-6e1f-39cf-8af3-85adaec6d3b3',\n",
       "       'e58e684a-509e-33c6-b88c-6d3c07d348bb',\n",
       "       'f03552d8-e216-300d-9548-4c0541a9c5b8',\n",
       "       '1e0e14bd-34a8-34a3-b17a-d13a9a29ed22',\n",
       "       '4843fc31-6392-369c-a2ee-eaa7a26ec7e1',\n",
       "       '0dfe8e63-d7a3-3fe4-b9d7-1b8122158f33',\n",
       "       'cce6a630-720f-3013-8b7b-1720b784cc86',\n",
       "       'c2a6bf5a-45ca-3f79-93ff-355a724b65df',\n",
       "       '11ac90f4-ea3d-3c82-8cf7-19f9c4da8ad0',\n",
       "       '148b41b3-3504-3550-9783-145eba1be802',\n",
       "       'e3976e74-e71b-34db-8e98-08dc422fa567',\n",
       "       '17c3be62-5893-3e43-a5a6-537780aef3ff',\n",
       "       'c83fb1c9-2b90-3dab-9d53-05a883e3e0b7',\n",
       "       '8b1dc5d0-dde1-31be-851f-a643ae235d50',\n",
       "       '9a9b0a97-3514-3137-b8b8-129474b24528',\n",
       "       '4aac459a-0536-355b-ad4a-834acf6cc4cf',\n",
       "       '522e9bea-52e1-3e3c-aa9f-e97e554195f7',\n",
       "       '915597ce-24e5-31fa-8dca-29437f49f839',\n",
       "       '37cba700-eed6-3018-bad6-f720f8217aeb',\n",
       "       '53a2a38b-4fef-3d65-8d6d-818d5e80dbfa',\n",
       "       'fd0ccbd0-3a58-3818-8691-98f31de17527',\n",
       "       'ae797830-f7a6-38f3-abf8-e1dc6cf3b6c3',\n",
       "       '0b1a7596-d9dc-37de-a154-90f3bfdc8ce6',\n",
       "       '794b93d6-2bea-3e7f-add7-b56fc6f4ae06',\n",
       "       'd9847b13-dc30-36e7-8d75-c632495a7eec',\n",
       "       'ff2a61d1-b70b-352b-8f08-ebc0a84de7ca',\n",
       "       '099b1c65-c060-3f5d-87cf-42bda251c3ea',\n",
       "       'da445603-1f91-341f-93da-6b29c95aa35c',\n",
       "       '87093480-2ef4-3d14-a30e-0c4cf41b93da',\n",
       "       '5c8ce3e9-f9dd-3ed2-b044-d55c2957937e',\n",
       "       '2cf91680-b719-3f92-9a56-dbbc9cd17b6c',\n",
       "       '0cfa3d00-10b5-38d5-b166-329ff6f4598b',\n",
       "       '592ec449-a3b0-3a40-afdc-2cf78ef8291e',\n",
       "       'd587e742-f07f-3037-b412-ac12c89f6e6a',\n",
       "       'f8b69e24-e2c0-3186-9578-380835eb2ee7',\n",
       "       'f2094a17-764b-3cba-8a2f-cf25ce4d1100',\n",
       "       '2444cdfb-370c-3f84-b97b-9462255688f2',\n",
       "       '653dadb9-5c19-3f6a-8207-7e55e7db331a',\n",
       "       '6f48fd66-a056-3172-af60-632f22844934'], dtype='<U36')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def general_pipeline():\n",
    "    train_json = open('./data/case_2_data_for_members.json')\n",
    "    train_vacancies = json.load(train_json)\n",
    "    model = CatBoostVacancyRanker()\n",
    "    model.fit(train_vacancies)\n",
    "\n",
    "    # Here we get our predictions from extractors\n",
    "\n",
    "    test_json = open('./data/case_2_reference_without_resume_sorted.json')\n",
    "    test_vacancies = json.load(test_json)\n",
    "\n",
    "    resumes = test_vacancies['resumes']\n",
    "    resumes_id = [resume['uuid'] for resume in resumes]\n",
    "\n",
    "    return model.predict(test_vacancies, resumes_id)\n",
    "\n",
    "general_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
